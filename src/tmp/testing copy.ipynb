{"cells":[{"cell_type":"code","execution_count":12,"metadata":{"id":"5bFoPVip9Ji_"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Dropout, add\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import matplotlib.pyplot as plt\n","from underthesea import word_tokenize\n","import shap\n","from lime import lime_image"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SPD_mZQS9Jlh"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded 296 images and 296 captions\n"]}],"source":["def load_dataset(base_path='../dataset'):\n","    image_paths = []\n","    captions = []\n","    for img_name in os.listdir(f'{base_path}/images'):\n","        if img_name.endswith('.jpg'):\n","            image_path = f'{base_path}/images/{img_name}'\n","            caption_path = f'{base_path}/captions/{img_name.replace(\".jpg\", \".txt\")}'\n","\n","            with open(caption_path, 'r') as f:\n","                caption = f.read()\n","\n","            image_paths.append(image_path)\n","            captions.append(caption)\n","\n","    return image_paths, captions\n","\n","image_paths, captions = load_dataset()\n","print(f'Loaded {len(image_paths)} images and {len(captions)} captions')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Vfaiwrqs9Jn9"},"outputs":[],"source":["def preprocess_image(img_path):\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    img_array = image.img_to_array(img)\n","    img_array_expanded = np.expand_dims(img_array, axis=0)\n","    return preprocess_input(img_array_expanded)\n","\n","resnet = ResNet50(weights='imagenet', include_top=False, pooling='avg')"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"0ku7e0H29JqT"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocab size: 279, Max length: 130\n","Original: Nhũ ảnh ghi lại sự biến dạng của mô đệm của vú trái, có đường kính 15 mm, tổn thương có tiêu chí nghi ngờ trung gian.  Kết quả hình ảnh lành tính BiRads 2.\n","Tokenized: ['<start>', 'Nhũ', 'ảnh', 'ghi', 'lại', 'sự', 'biến dạng', 'của', 'mô đệm', 'của', 'vú', 'trái', ',', 'có', 'đường kính', '15', 'mm', ',', 'tổn thương', 'có', 'tiêu chí', 'nghi ngờ', 'trung gian', '.', 'Kết quả', 'hình ảnh', 'lành tính', 'BiRads', '2', '.', '<end>']\n","Padded: [  6  21  22 117 103  59 161  45 162  45   5  42   3   4  51 128  39   3\n","  63   4 129  32 147   2  20   8  14   9  19   2   7   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0]\n","\n","Original: Vôi hóa tổng thể lành tính được quan sát thấy ở cả hai bên. Không có hình ảnh nốt nào gợi ý ác tính, vôi hóa mô tuyến vú đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.\n","Tokenized: ['<start>', 'Vôi', 'hóa', 'tổng thể', 'lành tính', 'được', 'quan sát', 'thấy', 'ở', 'cả', 'hai', 'bên', '.', 'Không', 'có', 'hình ảnh', 'nốt', 'nào', 'gợi ý', 'ác tính', ',', 'vôi', 'hóa', 'mô', 'tuyến', 'vú', 'đáng', 'ngờ', 'hoặc', 'những', 'thay đổi', 'đáng kể', 'khác', 'được', 'xác định', 'ở', 'cả', 'hai', 'bên', '.', 'Kết quả', 'hình ảnh', 'lành tính', 'BiRads', '2', '.', '<end>']\n","Padded: [  6  31  16 163  14  27  65  55  10  26  17  24   2  13   4   8  12  29\n","  23  11   3  31  16  56  15   5  25  28  36  30  33  38  35  27  47  10\n","  26  17  24   2  20   8  14   9  19   2   7   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0]\n","\n","Original: Vôi hóa tổng thể lành tính được quan sát thấy ở cả hai bên. Không có hình ảnh nốt nào gợi ý ác tính, vôi hóa mô tuyến vú đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.\n","Tokenized: ['<start>', 'Vôi', 'hóa', 'tổng thể', 'lành tính', 'được', 'quan sát', 'thấy', 'ở', 'cả', 'hai', 'bên', '.', 'Không', 'có', 'hình ảnh', 'nốt', 'nào', 'gợi ý', 'ác tính', ',', 'vôi', 'hóa', 'mô', 'tuyến', 'vú', 'đáng', 'ngờ', 'hoặc', 'những', 'thay đổi', 'đáng kể', 'khác', 'được', 'xác định', 'ở', 'cả', 'hai', 'bên', '.', 'Kết quả', 'hình ảnh', 'lành tính', 'BiRads', '2', '.', '<end>']\n","Padded: [  6  31  16 163  14  27  65  55  10  26  17  24   2  13   4   8  12  29\n","  23  11   3  31  16  56  15   5  25  28  36  30  33  38  35  27  47  10\n","  26  17  24   2  20   8  14   9  19   2   7   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0]\n","\n"]}],"source":["# Tokenization và Padding cho tiếng Việt\n","tokenizer = Tokenizer(oov_token=\"<unk>\", filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n","captions_tokenized = [['<start>'] + word_tokenize(caption) + ['<end>'] for caption in captions]\n","tokenizer.fit_on_texts(captions_tokenized)\n","vocab_size = len(tokenizer.word_index) + 1\n","sequences = tokenizer.texts_to_sequences(captions_tokenized)\n","max_length = max(len(s) for s in sequences)\n","captions_padded = pad_sequences(sequences, maxlen=max_length, padding='post')\n","\n","print(f'Vocab size: {vocab_size}, Max length: {max_length}')\n","# print samples\n","for i in range(3):\n","    print(f'Original: {captions[i]}')\n","    print(f'Tokenized: {captions_tokenized[i]}')\n","    print(f'Padded: {captions_padded[i]}')\n","    print()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2021,"status":"ok","timestamp":1710689707632,"user":{"displayName":"Nghiem Thanh Pham","userId":"15555774540185830326"},"user_tz":-420},"id":"FdZHjGmk9Jsy","outputId":"b8005593-d111-48ac-dd89-12b4094c0548"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_3 (InputLayer)        [(None, 128)]                0         []                            \n","                                                                                                  \n"," input_2 (InputLayer)        [(None, 2048)]               0         []                            \n","                                                                                                  \n"," embedding (Embedding)       (None, 128, 256)             70912     ['input_3[0][0]']             \n","                                                                                                  \n"," dropout (Dropout)           (None, 2048)                 0         ['input_2[0][0]']             \n","                                                                                                  \n"," dropout_1 (Dropout)         (None, 128, 256)             0         ['embedding[0][0]']           \n","                                                                                                  \n"," dense (Dense)               (None, 256)                  524544    ['dropout[0][0]']             \n","                                                                                                  \n"," lstm (LSTM)                 (None, 256)                  525312    ['dropout_1[0][0]']           \n","                                                                                                  \n"," add (Add)                   (None, 256)                  0         ['dense[0][0]',               \n","                                                                     'lstm[0][0]']                \n","                                                                                                  \n"," dense_1 (Dense)             (None, 256)                  65792     ['add[0][0]']                 \n","                                                                                                  \n"," dense_2 (Dense)             (None, 277)                  71189     ['dense_1[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 1257749 (4.80 MB)\n","Trainable params: 1257749 (4.80 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["def build_model(vocab_size, max_length):\n","    # Image feature extractor layer\n","    inputs1 = Input(shape=(2048,))\n","    fe1 = Dropout(0.5)(inputs1)\n","    fe2 = Dense(256, activation='relu')(fe1)\n","\n","    # Sequence processor layer\n","    inputs2 = Input(shape=(max_length,))\n","    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n","    se2 = Dropout(0.5)(se1)\n","    se3 = LSTM(256)(se2)\n","\n","    # Decoder layer\n","    decoder1 = add([fe2, se3])\n","    decoder2 = Dense(256, activation='relu')(decoder1)\n","    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n","\n","    # Tie it together [image, seq] [word]\n","    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n","    model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","    return model\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","model = build_model(vocab_size, max_length)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"of73gElv9JvT"},"outputs":[],"source":["image_features = {}\n","for img_path in image_paths:\n","    preprocessed_img = preprocess_image(img_path)\n","    features = resnet.predict(preprocessed_img, verbose=0)\n","    image_id = img_path.split('/')[-1].split('.')[0]\n","    image_features[image_id] = features\n","\n","images = list(image_features.keys())"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"ByXyDaYX9Jxt"},"outputs":[],"source":["from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","def data_generator(captions, image_features, tokenizer, max_length, batch_size):\n","    X1, X2, y = list(), list(), list()\n","    counter = 0  # Sử dụng biến counter thay vì n để đếm số lượng mẫu trong batch\n","    while True:\n","        for i, caption in enumerate(captions):\n","            image_id = images[i]\n","            photo = image_features[image_id][0]\n","            seq = tokenizer.texts_to_sequences([caption])[0]\n","\n","            for j in range(1, len(seq)):  # Sử dụng biến lặp j thay vì i trong vòng lặp này\n","                in_seq, out_seq = seq[:j], seq[j]\n","                in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n","                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n","\n","                X1.append(photo)\n","                X2.append(in_seq)\n","                y.append(out_seq)\n","                counter += 1\n","\n","                if counter == batch_size:\n","                    yield [[np.array(X1), np.array(X2)], np.array(y)]\n","                    X1, X2, y = list(), list(), list()\n","                    counter = 0  # Đặt lại counter về 0 sau khi đủ kích thước batch\n","\n","# Sử dụng tên biến khác nhau cho vòng lặp trong hàm data_generator"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":581002,"status":"ok","timestamp":1710690558396,"user":{"displayName":"Nghiem Thanh Pham","userId":"15555774540185830326"},"user_tz":-420},"id":"_4N7rg4P6Lb7","outputId":"33641088-24b9-44b2-c786-af6ccc343403"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n"]},{"name":"stderr","output_type":"stream","text":["`Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 193, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/81/p37gc41n4ds1pfphccjpd46w0000gn/T/ipykernel_93850/2409195196.py\", line 6, in <module>\n      model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 2810, in fit_generator\n      return self.fit(\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/backend.py\", line 5566, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[10,277] labels_size=[10,279]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_32774]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m data_generator(train_captions, image_features, tokenizer, max_length, batch_size)\n\u001b[1;32m     37\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m data_generator(test_captions, image_features, tokenizer, max_length, batch_size)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Sử dụng SHAP và LIME để giải thích dự đoán\u001b[39;00m\n\u001b[1;32m     42\u001b[0m X_sample, y_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_generator(test_captions, image_features, tokenizer, max_length, \u001b[38;5;241m1\u001b[39m))\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py:2810\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2799\u001b[0m \n\u001b[1;32m   2800\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2806\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2808\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2809\u001b[0m )\n\u001b[0;32m-> 2810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2812\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 193, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/81/p37gc41n4ds1pfphccjpd46w0000gn/T/ipykernel_93850/2409195196.py\", line 6, in <module>\n      model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 2810, in fit_generator\n      return self.fit(\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/Users/nghiempt/Library/Python/3.8/lib/python/site-packages/keras/src/backend.py\", line 5566, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[10,277] labels_size=[10,279]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_32774]"]}],"source":["# from sklearn.model_selection import train_test_split\n","\n","# train_image_paths, test_image_paths, train_captions, test_captions = train_test_split(image_paths, captions, test_size=0.2, random_state=42)\n","\n","# print(f'Training set: {len(train_image_paths)} images, {len(train_captions)} captions')\n","# print(f'Testing set: {len(test_image_paths)} images, {len(test_captions)} captions')\n","\n","# batch_size = 10\n","# train_steps = len(train_captions) // batch_size\n","\n","# for i in range(2):\n","#     train_generator = data_generator(train_captions, image_features, tokenizer, max_length, batch_size)\n","#     model.fit_generator(train_generator, epochs=1, steps_per_epoch=train_steps, verbose=1)\n","\n","# test_steps = len(test_captions) // batch_size\n","# test_generator = data_generator(test_captions, image_features, tokenizer, max_length, batch_size)\n","# evaluation = model.evaluate_generator(test_generator, steps=test_steps, verbose=1)\n","\n","# print(\"Test Loss:\", evaluation)\n","\n","\n","\n","\n","from sklearn.model_selection import train_test_split\n","\n","batch_size = 10\n","\n","# Đảm bảo bạn đã chia dữ liệu thành tập huấn luyện và tập kiểm tra một cách chính xác\n","train_image_paths, test_image_paths, train_captions, test_captions = train_test_split(image_paths, captions, test_size=0.2, random_state=42)\n","\n","# Số lượng batch và bước huấn luyện\n","train_steps = len(train_captions) // batch_size\n","test_steps = len(test_captions) // batch_size\n","\n","# Đào tạo mô hình\n","train_generator = data_generator(train_captions, image_features, tokenizer, max_length, batch_size)\n","test_generator = data_generator(test_captions, image_features, tokenizer, max_length, batch_size)\n","\n","model.fit_generator(train_generator, epochs=2, steps_per_epoch=train_steps, validation_data=test_generator, validation_steps=test_steps)\n","\n","# Sử dụng SHAP và LIME để giải thích dự đoán\n","X_sample, y_sample = next(data_generator(test_captions, image_features, tokenizer, max_length, 1))\n","X_sample_image, X_sample_text = X_sample\n","\n","explainer = shap.DeepExplainer(model, [X_sample_image, X_sample_text])\n","shap_values = explainer.shap_values([X_sample_image, X_sample_text])\n","\n","# Hiển thị giải thích SHAP\n","shap.image_plot(shap_values[0], -X_sample_image)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Explain predictions using SHAP\n","explainer = shap.Explainer(model, image_features.values())\n","shap_values = explainer(image_features.values(), max_evals=2 * len(image_features) + 1)\n","\n","# Explain predictions using LIME\n","explainer = lime_image.LimeImageExplainer()\n","explanation = explainer.explain_instance(image, model.predict, top_labels=5, hide_color=0, num_samples=1000)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Input 1 of layer \"model\" is incompatible with the layer: expected shape=(None, 128), found shape=(410, 130)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m X_sample_image, X_sample_text \u001b[38;5;241m=\u001b[39m X_sample\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Áp dụng SHAP\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_sample_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_sample_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Lấy dự đoán cho một ví dụ cụ thể\u001b[39;00m\n\u001b[1;32m     10\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values([X_sample_image, X_sample_text])\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/shap/explainers/_deep/__init__.py:84\u001b[0m, in \u001b[0;36mDeepExplainer.__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     81\u001b[0m         framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mTFDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_phase_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m PyTorchDeep(model, data)\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/shap/explainers/_deep/deep_tf.py:162\u001b[0m, in \u001b[0;36mTFDeep.__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;66;03m#if type(self.model)is tuple:\u001b[39;00m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;66;03m#    self.fModel(cnn.inputs, cnn.get_layer(theNameYouWant).outputs)\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_between_tensors(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_output\u001b[38;5;241m.\u001b[39mop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_inputs)\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/src/engine/input_spec.py:298\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 298\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         )\n","\u001b[0;31mValueError\u001b[0m: Input 1 of layer \"model\" is incompatible with the layer: expected shape=(None, 128), found shape=(410, 130)"]}],"source":["# Trích xuất dữ liệu từ generator và chuyển đổi thành mảng NumPy\n","data_gen = data_generator(train_captions, image_features, tokenizer, max_length, batch_size)\n","X_sample, y_sample = next(data_gen)\n","X_sample_image, X_sample_text = X_sample\n","\n","# Áp dụng SHAP\n","explainer = shap.DeepExplainer(model, [X_sample_image, X_sample_text])\n","\n","# Lấy dự đoán cho một ví dụ cụ thể\n","shap_values = explainer.shap_values([X_sample_image, X_sample_text])\n","\n","# Hiển thị giải thích SHAP\n","shap.image_plot(shap_values[0], -X_sample_image)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"nbformat":4,"nbformat_minor":0}
