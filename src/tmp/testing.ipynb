{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23361,"status":"ok","timestamp":1710685742109,"user":{"displayName":"Nghiem Thanh Pham","userId":"15555774540185830326"},"user_tz":-420},"id":"oUFsNypcyu9c","outputId":"30de6f48-bd7d-45c9-c394-366849b31eb1"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"5bFoPVip9Ji_"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Dropout, add\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"SPD_mZQS9Jlh"},"outputs":[],"source":["def load_dataset(base_path='Inbreast'):\n","    image_paths = []\n","    captions = []\n","    for img_name in os.listdir(f'{base_path}/image'):\n","        if img_name.endswith('.jpg'):\n","            image_path = f'{base_path}/image/{img_name}'\n","            caption_path = f'{base_path}/caption/{img_name.replace(\".jpg\", \".txt\")}'\n","\n","            with open(caption_path, 'r') as f:\n","                caption = f.read()\n","\n","            image_paths.append(image_path)\n","            captions.append(caption)\n","\n","    return image_paths, captions\n","\n","image_paths, captions = load_dataset()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Vfaiwrqs9Jn9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 5s 0us/step\n"]}],"source":["def preprocess_image(img_path):\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    img_array = image.img_to_array(img)\n","    img_array_expanded = np.expand_dims(img_array, axis=0)\n","    return preprocess_input(img_array_expanded)\n","\n","resnet = ResNet50(weights='imagenet', include_top=False, pooling='avg')"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"0ku7e0H29JqT"},"outputs":[],"source":["tokenizer = Tokenizer(num_words=5000, oov_token=\"<unk>\")\n","tokenizer.fit_on_texts(captions)\n","sequences = tokenizer.texts_to_sequences(captions)\n","max_length = max(len(s) for s in sequences)\n","captions_padded = pad_sequences(sequences, maxlen=max_length, padding='post')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2021,"status":"ok","timestamp":1710689707632,"user":{"displayName":"Nghiem Thanh Pham","userId":"15555774540185830326"},"user_tz":-420},"id":"FdZHjGmk9Jsy","outputId":"b8005593-d111-48ac-dd89-12b4094c0548"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_3 (InputLayer)        [(None, 139)]                0         []                            \n","                                                                                                  \n"," input_2 (InputLayer)        [(None, 2048)]               0         []                            \n","                                                                                                  \n"," embedding (Embedding)       (None, 139, 256)             70656     ['input_3[0][0]']             \n","                                                                                                  \n"," dropout (Dropout)           (None, 2048)                 0         ['input_2[0][0]']             \n","                                                                                                  \n"," dropout_1 (Dropout)         (None, 139, 256)             0         ['embedding[0][0]']           \n","                                                                                                  \n"," dense (Dense)               (None, 256)                  524544    ['dropout[0][0]']             \n","                                                                                                  \n"," lstm (LSTM)                 (None, 256)                  525312    ['dropout_1[0][0]']           \n","                                                                                                  \n"," add (Add)                   (None, 256)                  0         ['dense[0][0]',               \n","                                                                     'lstm[0][0]']                \n","                                                                                                  \n"," dense_1 (Dense)             (None, 256)                  65792     ['add[0][0]']                 \n","                                                                                                  \n"," dense_2 (Dense)             (None, 276)                  70932     ['dense_1[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 1257236 (4.80 MB)\n","Trainable params: 1257236 (4.80 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["def build_model(vocab_size, max_length):\n","    # Image feature extractor layer\n","    inputs1 = Input(shape=(2048,))\n","    fe1 = Dropout(0.5)(inputs1)\n","    fe2 = Dense(256, activation='relu')(fe1)\n","\n","    # Sequence processor layer\n","    inputs2 = Input(shape=(max_length,))\n","    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n","    se2 = Dropout(0.5)(se1)\n","    se3 = LSTM(256)(se2)\n","\n","    # Decoder layer\n","    decoder1 = add([fe2, se3])\n","    decoder2 = Dense(256, activation='relu')(decoder1)\n","    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n","\n","    # Tie it together [image, seq] [word]\n","    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n","    model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","    return model\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","model = build_model(vocab_size, max_length)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"of73gElv9JvT"},"outputs":[],"source":["image_features = {}\n","for img_path in image_paths:\n","    preprocessed_img = preprocess_image(img_path)\n","    features = resnet.predict(preprocessed_img, verbose=0)\n","    image_id = img_path.split('/')[-1].split('.')[0]\n","    image_features[image_id] = features\n","\n","images = list(image_features.keys())"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ByXyDaYX9Jxt"},"outputs":[],"source":["from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","def data_generator(captions, image_features, tokenizer, max_length, batch_size):\n","    X1, X2, y = list(), list(), list()\n","    n=0\n","    while 1:\n","        for i, caption in enumerate(captions):\n","            n+=1\n","            image_id = images[i]\n","            photo = image_features[image_id][0]\n","            seq = tokenizer.texts_to_sequences([caption])[0]\n","\n","            for i in range(1, len(seq)):\n","                in_seq, out_seq = seq[:i], seq[i]\n","                in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n","                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n","\n","                X1.append(photo)\n","                X2.append(in_seq)\n","                y.append(out_seq)\n","\n","            if n == batch_size:\n","                yield [[np.array(X1), np.array(X2)], np.array(y)]\n","                X1, X2, y = list(), list(), list()\n","                n=0"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":581002,"status":"ok","timestamp":1710690558396,"user":{"displayName":"Nghiem Thanh Pham","userId":"15555774540185830326"},"user_tz":-420},"id":"_4N7rg4P6Lb7","outputId":"33641088-24b9-44b2-c786-af6ccc343403"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/81/p37gc41n4ds1pfphccjpd46w0000gn/T/ipykernel_92799/2409195196.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n"]},{"name":"stdout","output_type":"stream","text":["296/296 [==============================] - 95s 306ms/step - loss: 4.1864\n","296/296 [==============================] - 129s 436ms/step - loss: 2.3003\n"]}],"source":["batch_size = 1\n","steps = len(captions) // batch_size\n","\n","for i in range(2):\n","    generator = data_generator(captions, image_features, tokenizer, max_length, batch_size)\n","    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from rouge) (1.15.0)\n","Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install rouge"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"hTz6EZSgEHn7"},"outputs":[],"source":["from nltk.translate.bleu_score import corpus_bleu\n","from rouge import Rouge\n","import numpy as np"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"E04DgU4eEHqh"},"outputs":[],"source":["def generate_caption(image_path, model, tokenizer, max_length):\n","    photo = preprocess_image(image_path)\n","    photo_feature = resnet.predict(photo, verbose=0)\n","\n","    in_text = '<start>'\n","    for _ in range(max_length):\n","        sequence = tokenizer.texts_to_sequences([in_text])[0]\n","        sequence = pad_sequences([sequence], maxlen=max_length)\n","        yhat = model.predict([photo_feature, sequence], verbose=0)\n","        yhat = np.argmax(yhat)\n","        word = tokenizer.index_word.get(yhat, None)\n","        if word is None:\n","            break\n","        in_text += ' ' + word\n","        if word == '<end>':\n","            break\n","    return in_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NhcDVVErEHs5"},"outputs":[],"source":["def evaluate_model(model, captions, image_features, tokenizer, max_length):\n","    actual, predicted = list(), list()\n","    rouge = Rouge()\n","\n","    for i, caption in enumerate(captions):\n","        image_id = images[i]\n","        image_path = image_paths[i]\n","\n","        yhat = generate_caption(image_path, model, tokenizer, max_length)\n","\n","        references = [caption.split()]\n","        actual.append(references)\n","        predicted.append(yhat.split())\n","\n","    bleu_score = corpus_bleu(actual, predicted)\n","    print(f'BLEU Score: {bleu_score}')\n","\n","    actual_rouge = [' '.join(a[0]) for a in actual]\n","    predicted_rouge = [' '.join(p) for p in predicted]\n","\n","    rouge_score = rouge.get_scores(predicted_rouge, actual_rouge, avg=True)\n","    print(f'ROUGE Score: {rouge_score}')\n","\n","evaluate_model(model, captions, image_features, tokenizer, max_length)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting py-rouge\n","  Downloading py_rouge-1.1-py3-none-any.whl.metadata (8.7 kB)\n","Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m942.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: py-rouge\n","Successfully installed py-rouge-1.1\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install py-rouge"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['Inbreast/image/50998113_66adfbb4f19c76d2_MG_L_CC_ANON.jpg', 'Inbreast/image/22613918_f23fa352e7de3dc7_MG_R_CC_ANON.jpg', 'Inbreast/image/53587131_7b71aa9928e6975e_MG_L_CC_ANON.jpg', 'Inbreast/image/53582395_3f0db31711fc9795_MG_L_ML_ANON.jpg', 'Inbreast/image/50999273_cb65e8dac169f596_MG_R_ML_ANON.jpg', 'Inbreast/image/20587544_d571b5880ad2a016_MG_R_CC_ANON.jpg', 'Inbreast/image/50997823_cbb6c98a81e69eeb_MG_R_CC_ANON.jpg', 'Inbreast/image/51049682_6f64793857feb5d0_MG_L_CC_ANON.jpg', 'Inbreast/image/53586361_dda3c6969a34ff8e_MG_L_ML_ANON.jpg', 'Inbreast/image/22579870_301f1776aebbf5d2_MG_L_CC_ANON.jpg', 'Inbreast/image/24055203_606e9b184978a350_MG_L_CC_ANON.jpg', 'Inbreast/image/22678980_b9a4da5f2dae63a9_MG_L_CC_ANON.jpg', 'Inbreast/image/24055502_ac3185e18ffdc7b6_MG_R_CC_ANON.jpg', 'Inbreast/image/24065407_83db89f57aea498a_MG_R_ML_ANON.jpg', 'Inbreast/image/22670511_7e677f3d530e41ed_MG_L_ML_ANON.jpg', 'Inbreast/image/20587054_b6a4f750c6df4f90_MG_R_CC_ANON.jpg', 'Inbreast/image/50996800_fdf4a1516f88b280_MG_L_ML_ANON.jpg', 'Inbreast/image/22670278_98429c0bdf78c0c7_MG_R_CC_ANON.jpg', 'Inbreast/image/22670465_7e677f3d530e41ed_MG_L_CC_ANON.jpg', 'Inbreast/image/53587104_7b71aa9928e6975e_MG_L_ML_ANON.jpg', 'Inbreast/image/20588562_bf1a6aaadb05e3df_MG_L_CC_ANON.jpg', 'Inbreast/image/53581151_3be876aecfaad4ca_MG_L_CC_ANON.jpg', 'Inbreast/image/50998322_1e4b534393d18753_MG_R_ML_ANON.jpg', 'Inbreast/image/24065761_5291e1aee2bbf5df_MG_R_CC_ANON.jpg', 'Inbreast/image/50997624_67cc8c9939d74a9a_MG_R_ML_ANON.jpg', 'Inbreast/image/24065584_d8205a09c8173f44_MG_L_CC_ANON.jpg', 'Inbreast/image/22614522_2dec4948fbe6336d_MG_L_CC_ANON.jpg', 'Inbreast/image/53582476_3f0db31711fc9795_MG_R_CC_ANON.jpg', 'Inbreast/image/20587346_e634830794f5c1bd_MG_R_ML_ANON.jpg', 'Inbreast/image/51049276_832ebce700241036_MG_L_ML_ANON.jpg', 'Inbreast/image/53587481_d2befe622e188943_MG_L_CC_ANON.jpg', 'Inbreast/image/22580218_5530d5782fc89dd7_MG_L_CC_ANON.jpg', 'Inbreast/image/26933801_f8bfddc28e8045c0_MG_L_CC_ANON.jpg', 'Inbreast/image/51049462_6f64793857feb5d0_MG_L_ML_ANON.jpg', 'Inbreast/image/53587663_5fb370d4c1c71974_MG_R_CC_ANON.jpg', 'Inbreast/image/22614127_6bd24a0a42c19ce1_MG_R_ML_ANON.jpg', 'Inbreast/image/51048891_f3e93e889a7746f0_MG_L_ML_ANON.jpg', 'Inbreast/image/20587492_d571b5880ad2a016_MG_R_ML_ANON.jpg', 'Inbreast/image/20587784_81cd83d2f4d78528_MG_R_ML_ANON.jpg', 'Inbreast/image/20587994_024ee3569b2605dc_MG_R_CC_ANON.jpg', 'Inbreast/image/50998349_1e4b534393d18753_MG_R_CC_ANON.jpg', 'Inbreast/image/26933830_f8bfddc28e8045c0_MG_R_ML_ANON.jpg', 'Inbreast/image/53586415_dda3c6969a34ff8e_MG_L_CC_ANON.jpg', 'Inbreast/image/24065833_c01f83a1eb283270_MG_L_ML_ANON.jpg', 'Inbreast/image/53582540_3e73f1c0670cfb0a_MG_R_ML_ANON.jpg', 'Inbreast/image/53582304_8913a7e0cf3bd74e_MG_R_ML_ANON.jpg', 'Inbreast/image/53586805_e5f3f68b9ce31228_MG_R_CC_ANON.jpg', 'Inbreast/image/50996854_fdf4a1516f88b280_MG_L_CC_ANON.jpg', 'Inbreast/image/50998258_f34ee0ab6591b792_MG_R_CC_ANON.jpg', 'Inbreast/image/24055779_f0f1a133837b5137_MG_L_CC_ANON.jpg', 'Inbreast/image/53587508_d2befe622e188943_MG_R_CC_ANON.jpg', 'Inbreast/image/50997277_9054942f7be52dd9_MG_L_CC_ANON.jpg', 'Inbreast/image/24055573_6f1aef40b3775182_MG_L_ML_ANON.jpg', 'Inbreast/image/50997651_67cc8c9939d74a9a_MG_L_CC_ANON.jpg', 'Inbreast/image/50997742_cbb6c98a81e69eeb_MG_L_ML_ANON.jpg', 'Inbreast/image/22614097_6bd24a0a42c19ce1_MG_L_CC_ANON.jpg', 'Inbreast/image/50999459_f62fbf38fb208316_MG_L_CC_ANON.jpg', 'Inbreast/image/53581914_21e6cc12630e5e9f_MG_L_CC_ANON.jpg', 'Inbreast/image/53586724_e5f3f68b9ce31228_MG_L_ML_ANON.jpg', 'Inbreast/image/22678953_b9a4da5f2dae63a9_MG_R_CC_ANON.jpg']\n","['một vùng nốt nằm ở phần chuyển tiếp của các góc phần tư bên trong của vú trái có đường kính 15 mm, với những phát hiện đáng ngờ về bệnh ác tính. Sinh thiết nghi ngờ ác tính BiRads 5.', 'nhũ ảnh tuyến vú ghi nhận một nhóm vi vôi hóa vú phải có đường kính 5 mm. Sinh thiết nghi ngờ lành tính BiRads 4a.', 'nhũ ảnh tuyến vú ghi nhận ít nhu mô vú, đa phần là mô mỡ, sự thoái triển mô tuyến vú ở cả hai bên. Không có hình ảnh nốt riêng lẻ nào gợi ý bệnh ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'Không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'Nhũ ảnh quan sát thấy có quá nhiều nhu mô tuyến vú. Những phát hiện này phản ánh hiện tượng thay đổi u xơ. Các nốt mờ gợi ý bệnh ác tính, vôi hóa vi mô đáng ngờ hoặc các thay đổi liên quan khác không được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'nhũ ảnh tuyến vú, hình ảnh các nốt mờ, giới hạn rõ, mật độ đồng nhất, gợi ý tính lành tính. Kết quả hình ảnh lành tính BiRads 3.', 'Nhũ ảnh mà không có những thay đổi khác. Kết quả hình ảnh lành tính BiRads 2.', 'không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'nhũ ảnh tuyến vú ghi lại một vùng có kích thước khoảng 11mm chứa các vi vôi hóa nằm trong của vú trái 1/4 trên ngoài, được nhóm lại, đa hình thái, với mật độ khác nhau. Sinh thiết nghi ngờ ác tính BiRads 4c.', 'Vi vôi hóa có kích thước khoảng 3 cm. sinh thiết nghi ngờ bệnh ác tính BiRads 5', 'Đậm độ dày, đặc biệt là ở các góc phần tư ngoài. Hình ảnh các đám mờ gợi ý bệnh ác tính, vi vôi hóa nghi ngờ ở hai bên. ', 'Tổn thương thứ nhất - nốt kích thước 13 mm của vú phải; Tổn thương thứ hai - nốt sần kích thước 11 mm của vú phải. Sinh thiết nghi ngờ ác tính BiRads 4c.', 'Sinh thiết nghi ngờ ác tính BiRads 4c', 'Nốt 1 của vú trái 40mm, đường viền gai Birads 5. Nốt 2 của vú trái 40mm, mật độ liên quan đến vi vôi hóa - Birads 5. Bệnh nhân đã được thực hiện phẫu thuật.', 'Nhũ ảnh ghi lại một cụm vi vôi hóa nằm ở vú phải có đường kính 2.5 cm. Sinh thiết nghi ngờ ác tính BiRads 4c.', 'không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2', 'Khối u ở vú phải, kích thước khoảng 20 mm, đáng ngờ. Sinh thiết nghi ngờ ác tính BiRads 4c.', 'Nốt 1 của vú trái 40mm, đường viền gai Birads 5. Nốt 2 của vú trái 40mm, mật độ liên quan đến vi vôi hóa - Birads 5. Bệnh nhân đã được thực hiện phẫu thuật.', 'nhũ ảnh tuyến vú ghi nhận ít nhu mô vú, đa phần là mô mỡ, sự thoái triển mô tuyến vú ở cả hai bên. Không có hình ảnh nốt riêng lẻ nào gợi ý bệnh ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'Sinh thiết tuyến vú trái đã được thực hiện', 'Nhũ ảnh được thực hiện ở vú trái, không có hình ảnh nào về các nốt mờ gợi ý ác tính. Kết quả hình ảnh lành tính BiRads 2.', 'Nhũ ảnh được thực hiện ở vú phải, không có hình ảnh nào về các nốt mờ gợi ý ác tính. Kết quả hình ảnh lành tính BiRads 2.', 'một nốt ở vú phải có đường kính 20 mm, phát hiện gợi ý về ác tính. Sinh thiết Nghi ngờ ác tính BiRads 5.', ' Không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'Vú trái có nốt có đường kính khoảng 5cm. Sinh thiết nghi ngờ ác tính BiRads 4c', 'một nốt nằm ở vú trái có đường kính 13 mm. sinh thiết nghi ngờ ác tínhBiRads 4a.', 'Không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'nhũ ảnh tuyến vú ghi nhận ít nhu mô vú, phần lớn là mô mỡ, chuyển thành các dấu hiệu của sự thoái triển tuyến vú ở cả hai bên, không có hình ảnh nốt riêng lẻ nào gợi ý bệnh ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác ở hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'Nhũ ảnh được thực hiện ở vú trái, không có hình ảnh nào về các nốt mờ gợi ý ác tính. Kết quả hình ảnh lành tính BiRads 2.', 'không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'nhũ ảnh tuyến vú có mật độ sợi tuyến phân tán, do số lượng nhu mô vú nhỏ, đa phần mô mỡ ở cả hai tuyến.', 'Nhũ ảnh vú để phân tích so sánh, giả định các đặc điểm giống hệt nhau, cụ thể là kích thước, hình thái và sự phân bố của các vi vôi hóa ở vú trái. Theo dõi hằng năm.', 'Nhũ ảnh mà không có những thay đổi khác. Kết quả hình ảnh lành tính BiRads 2.', 'Không có hình ảnh nốt nào gợi ý ác tính, vôi hóa mô tuyến vú đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'nhũ ảnh tuyến vú có mật độ sợi tuyến phân tán, do số lượng nhu mô vú nhỏ, đa phần là mô mỡ ở cả hai tuyến. Nghiên cứu siêu âm ghi lại Tổn thương thứ nhất là một thay đổi dạng nang sợi có kích thước 10 mm, ở phần chuyển tiếp của góc phần tư bên trong của vú phải, hình dạng không đều, có độ sâu phía trước, bờ giới hạn rõ, hướng song song với mặt phẳng da. Tổn thương thứ nhất có BiRads 2. Tổn thương thứ hai ở vú phải tương ứng với một nốt tròn tăng đậm độ kích thước 30 mm trên chụp nhũ ảnh tuyến vú, có độ sâu bên trong hoặc sâu, rìa có gai, không có cụm vi vôi hóa.sinh thiết nghi ngờ ác tính BiRads 5.', 'Nhũ ảnh quan sát thấy một lượng lớn nhu mô vú, với mô hình dày đặc không đồng nhất, đặc biệt là ở các vùng sau cực quang và các góc phần tư ngoài. Rất ít vi vôi hóa lành tính được quan sát thấy ở cả hai bên, không có đặc điểm bệnh lý hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'Nhũ ảnh quan sát thấy có quá nhiều nhu mô tuyến vú. Những phát hiện này phản ánh hiện tượng thay đổi u xơ. Các nốt mờ gợi ý bệnh ác tính, vôi hóa vi mô đáng ngờ hoặc các thay đổi liên quan khác không được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'Quan sát thấy một lượng lớn nhu mô vú, với mô hình dày đặc không đồng nhất, đặc biệt là ở các góc phần tư ngoài. sinh thiết lành tính BiRads 3.', 'Một nốt với biến dạng mô đệm, nằm ở vú phải có đường kính 2 cm, sinh thiết nghi ngờ ác tính BiRads 6.', 'Nhũ ảnh được thực hiện ở vú phải, không có hình ảnh nào về các nốt mờ gợi ý ác tính. Kết quả hình ảnh lành tính BiRads 2.', 'Nhũ ảnh vú để phân tích so sánh, giả định các đặc điểm giống hệt nhau, cụ thể là kích thước, hình thái và sự phân bố của các vi vôi hóa ở vú trái. Theo dõi hằng năm.', 'không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2', 'nhũ ảnh tuyến vú có mật độ sợi tuyến phân tán, do số lượng nhu mô tuyến vú nhỏ, đa phần mô mỡ. Không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'nhũ ảnh tuyến vú được thực hiện ở vú phải, không có hình ảnh nào về các nốt mờ gợi ý ác tính. Kết quả hình ảnh lành tính BiRads 2.', 'không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2', 'Nhũ ảnh quan sát thấy một lượng lớn nhu mô vú, với mô hình dày đặc không đồng nhất, đặc biệt là ở các vùng sau cực quang và các góc phần tư ngoài. Rất ít vi vôi hóa lành tính được quan sát thấy ở cả hai bên, không có đặc điểm bệnh lý hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'Da và mô tế bào dưới da có hình ảnh bình thường trên nhũ ảnh. Có những vi vôi hóa mà hình thái, mật độ và sự phân bố của chúng gợi ý đến sự lành tính và có thể quy cho các vi vôi hóa lành tính, trong bối cảnh những thay đổi về nang xơ. kết quả hình ảnh lành tính BiRads 2', 'không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'nhũ ảnh tuyến vú  cho thấy không có thay đổi đáng kể, với các đặc điểm lành tính. Kết quả hình ảnh lành tính BiRads 2.', 'sinh thiết nghi ngờ ác tính BiRads 4c.', ' Không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'nhũ ảnh tuyến vú, hình ảnh các nốt mờ, giới hạn rõ, mật độ đồng nhất, gợi ý tính lành tính. Kết quả hình ảnh lành tính BiRads 3.', 'nhũ ảnh tuyến vú có mật độ sợi tuyến phân tán, do số lượng nhu mô vú nhỏ, đa phần là mô mỡ ở cả hai tuyến. ', 'Sinh thiết nghi ngờ bệnh lý ác tính BiRads 5', 'Không có hình ảnh nào về các nốt nào gợi ý ác tính, vôi hóa mô đáng ngờ. Kết quả hình ảnh lành tính BiRads 2.', 'không có hình ảnh nốt nào gợi ý ác tính, vôi hóa vi mô đáng ngờ hoặc những thay đổi đáng kể khác được xác định ở cả hai bên. Kết quả hình ảnh lành tính BiRads 2.', 'Đậm độ dày, đặc biệt là ở các góc phần tư ngoài. Hình ảnh các đám mờ gợi ý bệnh ác tính, vi vôi hóa nghi ngờ ở hai bên. ']\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","# Tách dữ liệu huấn luyện thành dữ liệu huấn luyện và dữ liệu kiểm tra\n","train_image_paths, test_image_paths, train_captions, test_captions = train_test_split(image_paths, captions, test_size=0.2, random_state=42)\n","\n","# Sử dụng train_image_paths và train_captions để huấn luyện mô hình\n","# Sử dụng test_image_paths và test_captions để kiểm tra mô hình\n","print(test_image_paths)\n","print(test_captions)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from nltk.translate.bleu_score import corpus_bleu\n","from nltk.translate.meteor_score import meteor_score\n","from rouge import Rouge\n","from pycocoevalcap.cider.cider import Cider\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from underthesea import word_tokenize\n","\n","# Tính BLEU Score\n","def evaluate_bleu(model, image_features, test_captions_padded):\n","    references = [[caption.split() for caption in captions] for captions in test_captions]\n","    predictions = []\n","\n","    for i, image_path in enumerate(test_image_paths):\n","        image_id = image_path.split('/')[-1].split('.')[0]\n","        photo = np.array([image_features[image_id]])\n","        in_text = '<start>'\n","        for _ in range(max_length):\n","            sequence = tokenizer.texts_to_sequences([in_text])[0]\n","            sequence = pad_sequences([sequence], maxlen=max_length)\n","            yhat = model.predict([photo, sequence], verbose=0)\n","            yhat = np.argmax(yhat)\n","            word = word_for_id(yhat, tokenizer)\n","            if word is None:\n","                break\n","            in_text += ' ' + word\n","            if word == '<end>':\n","                break\n","        predictions.append(in_text.split())\n","\n","    return corpus_bleu(references, predictions)\n","\n","# Tính METEOR Score\n","def evaluate_meteor(model, image_features, test_captions_padded):\n","    predictions = []\n","\n","    for i, image_path in enumerate(test_image_paths):\n","        image_id = image_path.split('/')[-1].split('.')[0]\n","        photo = np.array([image_features[image_id]])\n","        in_text = '<start>'\n","        for _ in range(max_length):\n","            sequence = tokenizer.texts_to_sequences([in_text])[0]\n","            sequence = pad_sequences([sequence], maxlen=max_length)\n","            yhat = model.predict([photo, sequence], verbose=0)\n","            yhat = np.argmax(yhat)\n","            word = word_for_id(yhat, tokenizer)\n","            if word is None:\n","                break\n","            in_text += ' ' + word\n","            if word == '<end>':\n","                break\n","        predictions.append(in_text)\n","\n","    return meteor_score([caption for caption in test_captions], predictions)\n","\n","# Tính ROUGE Score\n","def evaluate_rouge(model, image_features, test_captions_padded):\n","    rouge = Rouge()\n","    references = [' '.join(caption) for caption in test_captions_tokenized]\n","    predictions = []\n","\n","    for i, image_path in enumerate(test_image_paths):\n","        image_id = image_path.split('/')[-1].split('.')[0]\n","        photo = np.array([image_features[image_id]])\n","        in_text = '<start>'\n","        for _ in range(max_length):\n","            sequence = tokenizer.texts_to_sequences([in_text])[0]\n","            sequence = pad_sequences([sequence], maxlen=max_length)\n","            yhat = model.predict([photo, sequence], verbose=0)\n","            yhat = np.argmax(yhat)\n","            word = word_for_id(yhat, tokenizer)\n","            if word is None:\n","                break\n","            in_text += ' ' + word\n","            if word == '<end>':\n","                break\n","        predictions.append(in_text)\n","\n","    scores = rouge.get_scores(predictions, references, avg=True)\n","    return scores\n","\n","# Tính CIDEr Score\n","def evaluate_cider(model, image_features, test_captions_padded):\n","    references = [' '.join(caption) for caption in test_captions_tokenized]\n","    predictions = []\n","\n","    for i, image_path in enumerate(test_image_paths):\n","        image_id = image_path.split('/')[-1].split('.')[0]\n","        photo = np.array([image_features[image_id]])\n","        in_text = '<start>'\n","        for _ in range(max_length):\n","            sequence = tokenizer.texts_to_sequences([in_text])[0]\n","            sequence = pad_sequences([sequence], maxlen=max_length)\n","            yhat = model.predict([photo, sequence], verbose=0)\n","            yhat = np.argmax(yhat)\n","            word = word_for_id(yhat, tokenizer)\n","            if word is None:\n","                break\n","            in_text += ' ' + word\n","            if word == '<end>':\n","                break\n","        predictions.append(in_text)\n","\n","    cider_scorer = Cider()\n","    cider_score, _ = cider_scorer.compute_score(references, predictions)\n","\n","    return cider_score\n","\n","# Chuẩn bị dữ liệu cho đánh giá\n","test_captions_tokenized = [word_tokenize(caption) for caption in test_captions]\n","test_sequences = tokenizer.texts_to_sequences(test_captions_tokenized)\n","test_captions_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n","\n","# Đánh giá mô hình\n","bleu_score = evaluate_bleu(model, image_features, test_captions_padded)\n","meteor_score = evaluate_meteor(model, image_features, test_captions_padded)\n","rouge_scores = evaluate_rouge(model, image_features, test_captions_padded)\n","# cider_score = evaluate_cider(model, image_features, test_captions_padded)\n","\n","print(\"BLEU Score:\", bleu_score)\n","print(\"METEOR Score:\", meteor_score)\n","print(\"ROUGE Scores:\", rouge_scores)\n","# print(\"CIDEr Score:\", cider_score)\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'lower'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m data_generator(captions_test, image_features, tokenizer, max_length, batch_size)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# # Huấn luyện mô hình\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# epochs = 10\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# history = model.fit(train_generator, epochs=epochs, steps_per_epoch=train_steps, validation_data=test_generator, validation_steps=test_steps)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Đánh giá mô hình trên tập kiểm tra\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss on test set:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy on test set:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","Cell \u001b[0;32mIn[14], line 12\u001b[0m, in \u001b[0;36mdata_generator\u001b[0;34m(captions, image_features, tokenizer, max_length, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m image_id \u001b[38;5;241m=\u001b[39m images[i]\n\u001b[1;32m     11\u001b[0m photo \u001b[38;5;241m=\u001b[39m image_features[image_id][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m seq \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexts_to_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcaption\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(seq)):\n\u001b[1;32m     15\u001b[0m     in_seq, out_seq \u001b[38;5;241m=\u001b[39m seq[:i], seq[i]\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"]}],"source":["# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n","from sklearn.model_selection import train_test_split\n","\n","image_paths_train, image_paths_test, captions_train, captions_test = train_test_split(image_paths, captions_padded, test_size=0.2, random_state=42)\n","\n","# Tạo generator cho tập huấn luyện và tập kiểm tra\n","batch_size = 32\n","train_steps = len(captions_train) // batch_size\n","test_steps = len(captions_test) // batch_size\n","\n","train_generator = data_generator(captions_train, image_features, tokenizer, max_length, batch_size)\n","test_generator = data_generator(captions_test, image_features, tokenizer, max_length, batch_size)\n","\n","# # Huấn luyện mô hình\n","# epochs = 10\n","# history = model.fit(train_generator, epochs=epochs, steps_per_epoch=train_steps, validation_data=test_generator, validation_steps=test_steps)\n","\n","# Đánh giá mô hình trên tập kiểm tra\n","loss, accuracy = model.evaluate(test_generator, steps=test_steps)\n","print(\"Loss on test set:\", loss)\n","print(\"Accuracy on test set:\", accuracy)\n","\n","# Vẽ biểu đồ loss và accuracy\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/nghiempt/nltk_data'\n    - '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/nltk_data'\n    - '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/share/nltk_data'\n    - '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[38], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Chuẩn bị dữ liệu cho đánh giá\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m test_captions_tokenized \u001b[38;5;241m=\u001b[39m [word_tokenize(caption) \u001b[38;5;28;01mfor\u001b[39;00m caption \u001b[38;5;129;01min\u001b[39;00m test_captions]\n\u001b[1;32m      9\u001b[0m test_sequences \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(test_captions_tokenized)\n\u001b[1;32m     10\u001b[0m test_captions_padded \u001b[38;5;241m=\u001b[39m pad_sequences(test_sequences, maxlen\u001b[38;5;241m=\u001b[39mmax_length, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[38], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Chuẩn bị dữ liệu cho đánh giá\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m test_captions_tokenized \u001b[38;5;241m=\u001b[39m [\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaption\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m caption \u001b[38;5;129;01min\u001b[39;00m test_captions]\n\u001b[1;32m      9\u001b[0m test_sequences \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(test_captions_tokenized)\n\u001b[1;32m     10\u001b[0m test_captions_padded \u001b[38;5;241m=\u001b[39m pad_sequences(test_sequences, maxlen\u001b[38;5;241m=\u001b[39mmax_length, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/nltk/tokenize/__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m     ]\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/nghiempt/nltk_data'\n    - '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/nltk_data'\n    - '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/share/nltk_data'\n    - '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"]}],"source":["from nltk.translate.bleu_score import corpus_bleu\n","from nltk.translate.meteor_score import meteor_score\n","from rouge import Rouge\n","# from nltk.translate.cider import Cider\n","from nltk.tokenize import word_tokenize\n","\n","# Chuẩn bị dữ liệu cho đánh giá\n","test_captions_tokenized = [word_tokenize(caption) for caption in test_captions]\n","test_sequences = tokenizer.texts_to_sequences(test_captions_tokenized)\n","test_captions_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n","\n","# Tính BLEU Score\n","def evaluate_bleu(model, image_features, test_captions_padded):\n","    references = [[caption.split() for caption in captions] for captions in test_captions_tokenized]\n","    predictions = []\n","\n","    for i, image_path in enumerate(test_image_paths):\n","        image_id = image_path.split('/')[-1].split('.')[0]\n","        photo = np.array([image_features[image_id]])\n","        in_text = '<start>'\n","        for _ in range(max_length):\n","            sequence = tokenizer.texts_to_sequences([in_text])[0]\n","            sequence = pad_sequences([sequence], maxlen=max_length)\n","            yhat = model.predict([photo, sequence], verbose=0)\n","            yhat = np.argmax(yhat)\n","            word = word_for_id(yhat, tokenizer)\n","            if word is None:\n","                break\n","            in_text += ' ' + word\n","            if word == '<end>':\n","                break\n","        predictions.append(in_text.split())\n","\n","    return corpus_bleu(references, predictions)\n","\n","# Tính METEOR Score\n","def evaluate_meteor(model, image_features, test_captions_padded):\n","    predictions = []\n","\n","    for i, image_path in enumerate(test_image_paths):\n","        image_id = image_path.split('/')[-1].split('.')[0]\n","        photo = np.array([image_features[image_id]])\n","        in_text = '<start>'\n","        for _ in range(max_length):\n","            sequence = tokenizer.texts_to_sequences([in_text])[0]\n","            sequence = pad_sequences([sequence], maxlen=max_length)\n","            yhat = model.predict([photo, sequence], verbose=0)\n","            yhat = np.argmax(yhat)\n","            word = word_for_id(yhat, tokenizer)\n","            if word is None:\n","                break\n","            in_text += ' ' + word\n","            if word == '<end>':\n","                break\n","        predictions.append(in_text)\n","\n","    return meteor_score([caption for caption in test_captions], predictions)\n","\n","# Tính ROUGE Score\n","def evaluate_rouge(model, image_features, test_captions_padded):\n","    rouge = Rouge()\n","    references = [' '.join(caption) for caption in test_captions_tokenized]\n","    predictions = []\n","\n","    for i, image_path in enumerate(test_image_paths):\n","        image_id = image_path.split('/')[-1].split('.')[0]\n","        photo = np.array([image_features[image_id]])\n","        in_text = '<start>'\n","        for _ in range(max_length):\n","            sequence = tokenizer.texts_to_sequences([in_text])[0]\n","            sequence = pad_sequences([sequence], maxlen=max_length)\n","            yhat = model.predict([photo, sequence], verbose=0)\n","            yhat = np.argmax(yhat)\n","            word = word_for_id(yhat, tokenizer)\n","            if word is None:\n","                break\n","            in_text += ' ' + word\n","            if word == '<end>':\n","                break\n","        predictions.append(in_text)\n","\n","    scores = rouge.get_scores(predictions, references, avg=True)\n","    return scores\n","\n","# Tính CIDEr Score\n","# def evaluate_cider(model, image_features, test_captions_padded):\n","#     references = [' '.join(caption) for caption in test_captions_tokenized]\n","#     predictions = []\n","\n","#     for i, image_path in enumerate(test_image_paths):\n","#         image_id = image_path.split('/')[-1].split('.')[0]\n","#         photo = np.array([image_features[image_id]])\n","#         in_text = '<start>'\n","#         for _ in range(max_length):\n","#             sequence = tokenizer.texts_to_sequences([in_text])[0]\n","#             sequence = pad_sequences([sequence], maxlen=max_length)\n","#             yhat = model.predict([photo, sequence], verbose=0)\n","#             yhat = np.argmax(yhat)\n","#             word = word_for_id(yhat, tokenizer)\n","#             if word is None:\n","#                 break\n","#             in_text += ' ' + word\n","#             if word == '<end>':\n","#                 break\n","#         predictions.append(in_text)\n","\n","#     cider_scorer = Cider()\n","#     cider_score, _ = cider_scorer.compute_score(references, predictions)\n","\n","#     return cider_score\n","\n","# Đánh giá mô hình\n","bleu_score = evaluate_bleu(model, image_features, test_captions_padded)\n","meteor_score = evaluate_meteor(model, image_features, test_captions_padded)\n","rouge_scores = evaluate_rouge(model, image_features, test_captions_padded)\n","# cider_score = evaluate_cider(model, image_features, test_captions_padded)\n","\n","print(\"BLEU Score:\", bleu_score)\n","print(\"METEOR Score:\", meteor_score)\n","print(\"ROUGE Scores:\", rouge_scores)\n","# print(\"CIDEr Score:\", cider_score)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"nbformat":4,"nbformat_minor":0}
